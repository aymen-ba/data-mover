spark-submit
--class HiveToHbaseJob
--master local[4]
data-mover_2.11-0.1.jar


/tmp/data/* ==> 100 fichiers (de 100 MO)  ===> 100 partitions ===> (--master Local[4])  ===> temps d'execution de job: 17min

/tmp/data/* ==> 100 fichiers (de 100 MO)  ===> 100 partitions ===> (--master Local[7])  ===> temps d'execution de job: WARN Executor: Issue communicating with driver in heartbeater

/tmp/data/* ==> 100 fichiers (de 100 MO)  ===> 100 partitions ===> coalesce: 4 partitions ===> (--master Local[4])  ===> temps d'execution de job: java.lang.OutOfMemoryError: GC overhead limit exceeded


/user/aymen/data/transactions.parquet ===> 1 file of 10GO: 87 hdfs blocks ===> 87 parttions (--master Local[4])  ===> temps d'execution de job:

/user/aymen/data/transactions.parquet ===> 1 file of 10GO: 87 hdfs blocks ===> 87 parttions (--master Local[7])  ===> temps d'execution de job: WARN Executor: Issue communicating with driver in heartbeater


spark-submit --packages com.hortonworks:shc-core:1.1.1-2.1-s_2.11
 --repositories https://repo.hortonworks.com/content/groups/public/
 --conf spark.eventLog.enabled=false
  --class HiveToHbaseJob
   data-mover_2.11-1.0.jar
